{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSMazur/Nearest-Neighbors/blob/main/Nearest_Neighbors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HelloRob Project 4, Part 1: Nearest Neighbors\n",
        "\n",
        "This notebook is part of [HelloRob Project 4](https://hellorob.org/projects/p4). In it, you will implement the Nearest Neighbors machine learning algorithm in Python.\n",
        "\n",
        "This part of the project is completed individually. Before submitting the assignment, make sure to run all the cells.\n",
        "\n",
        "To start, edit the cell below by adding your name."
      ],
      "metadata": {
        "id": "auyoHuotO7p2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Name:**\n"
      ],
      "metadata": {
        "id": "uwr52RsplS6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "Some imports we'll need. Run this cell first."
      ],
      "metadata": {
        "id": "fa-0-ueQjr40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfsf7CiBhPnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions.\n",
        "\n",
        "This function helps visualize images. Run this cell before you start."
      ],
      "metadata": {
        "id": "4Z0x6DsgHoYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_image_grid(imgs, nrows=1, border_size=2):\n",
        "    N, H, W = imgs.shape\n",
        "    ncols = int(np.ceil(N / nrows))\n",
        "    pad = border_size // 2\n",
        "    imgs = (imgs * 255 / imgs.max()).astype(np.uint8)\n",
        "    padded = np.pad(imgs, ((0, 0), (pad, pad), (pad, pad)), 'constant', constant_values=255)\n",
        "    if N < ncols * nrows:\n",
        "        _, H, W = padded.shape\n",
        "        padded = np.concatenate((padded, np.zeros((ncols * nrows - N, H, W), dtype=padded.dtype)))\n",
        "    grid = np.vstack([np.hstack(padded[r * ncols:(r + 1) * ncols]) for r in range(nrows)])\n",
        "\n",
        "    return grid"
      ],
      "metadata": {
        "id": "dXIBtXe7KvVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The MNIST Data\n",
        "\n",
        "MNIST contains 60,000 train images and 10,000 test images. We will use a smaller subset of the dataset with `N_train` training images and `N_test` test images, because testing on the full dataset will take too long. You can modify these numbers when testing your algorithm.\n",
        "\n",
        "The images which we will use in this project are stored in matrices, `x_train` and `x_test`. These are 3 dimensional matrices, of shape `(N, W, H)`. You can think of these matrices as a _list_ of images of size `(W, H)`, with `H` rows and `W` columns.\n",
        "\n",
        "This data loading cell does some processing on the data to prepare it for use in this assignment. It initializes a few variables that you can use in later cells:\n",
        "* `N_train` and `N_test`: The number of testing and training images\n",
        "* `width`, `height`, and `DIM`: The width, height, and total number of pixels in the images (note `DIM = width * height`).\n",
        "* `num_classes`: The number of classes in the dataset (10)\n",
        "* `x_train`: The training images, with shape `(N_train, 28, 28)`\n",
        "* `y_train`: The training labels, a vector of length `N_train`\n",
        "* `x_test`: The testing images, with shape `(N_test, 28, 28)`\n",
        "* `y_test`: The testing labels, a vector of length `N_test`\n",
        "\n",
        "Each pixel value in the images is a float between 0 and 1. The variables `y_train` and `y_test` contain integers corresponding to the labels for each of the images, between 0 and 9."
      ],
      "metadata": {
        "id": "NXtLhDvkjvMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of test and train samples to use in this notebook.\n",
        "# TODO: Once your algorithm is implemented, come back to this cell and change\n",
        "# these numbers. They cannot be higher than N_train_full and N_test_full.\n",
        "N_train = 1000\n",
        "N_test = 50\n",
        "\n",
        "# Number of test and train samples available in MNIST\n",
        "num_classes = 10\n",
        "\n",
        "# Load dataset.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert to values from 0 to 1.\n",
        "x_train = x_train.astype(float) / 255\n",
        "x_test = x_test.astype(float) / 255\n",
        "\n",
        "# Grab the height and the width from the data.\n",
        "N_train_full, width, height = x_train.shape\n",
        "N_test_full, = y_test.shape\n",
        "DIM = width * height\n",
        "\n",
        "# Load subset (to cut down on computation time)\n",
        "train_index = np.random.choice(np.arange(N_train_full), N_train)\n",
        "test_index = np.random.choice(np.arange(N_test_full), N_test)\n",
        "\n",
        "x_train = x_train[train_index, :, :]\n",
        "y_train = y_train[train_index]\n",
        "x_test = x_test[test_index, :, :]\n",
        "y_test = y_test[test_index]\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)\n",
        "print(\"Testing labels shape:\", y_test.shape)\n",
        "\n",
        "# Visualize the first 100 training images.\n",
        "img_grid = make_image_grid(x_train[:100], nrows=10)\n",
        "plt.imshow(img_grid, cmap=plt.get_cmap('gray'))\n",
        "plt.title(\"The first 100 training images\")\n",
        "plt.axis('off');  # Adding a semi-colon after the last line stops a print."
      ],
      "metadata": {
        "id": "CFo2p7ADn36O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access a single image, we can index into the first dimension, and select all the pixels in the last two dimensions. We can index into the label like a regular vector. For example, to get the first training image and its label, we can use the code in the following cell."
      ],
      "metadata": {
        "id": "qdkfymA7oBW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first image and its label.\n",
        "img = x_train[0, :, :]\n",
        "label = y_train[0]\n",
        "\n",
        "print(\"The first image has shape:\", img.shape)\n",
        "\n",
        "print(\"The first image has label:\", label)\n",
        "# Display the image.\n",
        "plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "hatqA5WDoCdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance function\n",
        "\n",
        "The nearest neighbors algorithm requires a measure of distance between two images. We will use the $N$-dimensional Euclidean distance. Given two vectors of length $N$, $\\textbf{u}$ and $\\textbf{v}$, the Euclidean distance between them is:\n",
        "\n",
        "$$d(\\textbf{u}, \\textbf{v}) = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + \\dots (u_N - v_N)^2}$$\n",
        "\n",
        "For matrices, the same function applies, but we will sum the squares of the distances between each pixel.\n",
        "\n",
        "Complete the function `compute_distances()` such that it accepts an image, `X`, and a matrix of `N` images, `X_train`, and returns a vector of length `N` containing the Euclidean distance from `X` to each image in `X_train`.\n",
        "\n",
        "*Hint:* You can do this using multiple Python `for` loops, but it will take a very long time! You can do this with just one `for` loop using NumPy's batch computation features, like in the in-class activity. It is also possible to do it with no `for` loops!"
      ],
      "metadata": {
        "id": "ohqTNA9JxiW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    compute_distances(X, X_train)\n",
        "\n",
        "Compute Euclidean distances between an image and multiple training images.\n",
        "\n",
        "# Arguments\n",
        "- X: The image data, with shape (W, H).\n",
        "- X_train: The training images, with shape (N_train, W, H).\n",
        "\n",
        "# Outputs\n",
        "- dists: An array of the distances between an image and each image in X_train,\n",
        "         of length (N_train,).\n",
        "\"\"\"\n",
        "def compute_distances(X, X_train):\n",
        "    N, H, W = X_train.shape\n",
        "    dists = np.zeros(N)\n",
        "\n",
        "    # TODO: Compute the distance from `X` to each image in `X_train` and store\n",
        "    # the result in `dists`.\n",
        "\n",
        "    return dists"
      ],
      "metadata": {
        "id": "fZBczuGAyMKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nearest Neighbors\n",
        "\n",
        "The function `nearest_neighbor()` should use the `compute_distances()` function to get the distances from image `X` to each image in `X_train`. Then, it should return the _index_ of the image in `X_train` with the _smallest_ distance to `X`. (_Hint_: Consider the NumPy function [argmin](https://numpy.org/doc/stable/reference/generated/numpy.argmin.html).)"
      ],
      "metadata": {
        "id": "dBaM-o8LyhsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    nearest_neighbor(X, X_train)\n",
        "\n",
        "Compute the index of X's nearest neighbor in X_train.\n",
        "\n",
        "# Arguments\n",
        "- X: The image data, with shape (W, H).\n",
        "- X_train: The training images, with shape (N_train, W, H).\n",
        "\n",
        "# Output\n",
        "- min_img_idx: The index of the training image with the minimum distance to the\n",
        "               given image, a single integer number\n",
        "\"\"\"\n",
        "def nearest_neighbor(X, X_train):\n",
        "    min_img_idx = None\n",
        "\n",
        "    # TODO: Find the index of the nearest neighbor of `X` in `X_train` and\n",
        "    # store it in `min_img_idx`.\n",
        "\n",
        "    return min_img_idx"
      ],
      "metadata": {
        "id": "4KDoiLiwyiiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the distance and neighbor functions\n",
        "\n",
        "This data is small enough that you can deduce the correct answers through observation to make sure your functions return the right thing. Feel free to modify these to test more cases.\n",
        "\n",
        "For example, this block of code creates 2x2 matrix `mini_x = [1 2; 3 4]`, and matrix `mini_x_train` with shape `(3, 2, 2)`, containing matrices `[2 2; 3 3]`, `[1 1; 3 4]` and `[1 2; 3 4]`.\n",
        "\n",
        "The distances from `mini_x` to each `mini_x_train` should be `[sqrt(2), 1.0, 0]`. The nearest neighbor index for `mini_x` in `mini_x_train` is 2."
      ],
      "metadata": {
        "id": "-9_QGTtFy-9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some tests to make sure the functions are correct.\n",
        "mini_x = np.arange(1, 5).reshape(2, 2)\n",
        "mini_x_train = np.array([[[2, 2], [3, 3]],\n",
        "                         [[1, 1], [3, 4]],\n",
        "                         [[1, 2], [3, 4]]])\n",
        "dists = compute_distances(mini_x, mini_x_train)\n",
        "\n",
        "print(\"Test image:\\n\", mini_x)\n",
        "for i in range(mini_x_train.shape[0]):\n",
        "    print(\"Train image {}:\\n\".format(i), mini_x_train[i])\n",
        "\n",
        "print(\"Distances:\", dists)\n",
        "\n",
        "# Test nearest neighbors for one test image.\n",
        "nearest = nearest_neighbor(mini_x, mini_x_train)\n",
        "print(\"Nearest neighbor:\", nearest)"
      ],
      "metadata": {
        "id": "nUcv65qKzDLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize some images and their nearest neighbors."
      ],
      "metadata": {
        "id": "ZV-XxP74zMcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_viz = 10\n",
        "\n",
        "# Pick num_viz random images without replacement.\n",
        "idx = np.random.choice(np.arange(N_test), num_viz)\n",
        "vis_images = x_test[idx, :, :]\n",
        "\n",
        "# Find the nearest neighbors.\n",
        "nearest = [nearest_neighbor(vis_images[i], x_train) for i in range(num_viz)]\n",
        "nearest_imgs = x_train[nearest, :, :]\n",
        "\n",
        "# Visualize.\n",
        "print(\"Top row = test image, bottom row = nearest neighbor.\")\n",
        "img_grid = make_image_grid(np.concatenate((vis_images, nearest_imgs)), nrows=2)\n",
        "plt.imshow(img_grid, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "_eo_TxlxzREW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Nearest Neighbor Labels\n",
        "\n",
        "The `predict_nn_labels()` function should use the `nearest_neighbors()` function to find the nearest neighbors in `X_train` for each image in `X_test`. Then, it should assign the label of the nearest neighbor as the predicted label for each test image."
      ],
      "metadata": {
        "id": "J7J5JC841Bxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    predict_nn_labels(X_test, X_train, y_train)\n",
        "\n",
        "Predict nearest neighbor labels for X_test.\n",
        "\n",
        "# Arguments\n",
        "- X_test: The test images, with shape (N_test, D).\n",
        "- X_train: The training images, with shape (N_train, D).\n",
        "- y_train: The training labels, with shape (N_train,).\n",
        "\n",
        "# Outputs\n",
        "- labels: An array of predicted label for each testing image, with length N_test\n",
        "\"\"\"\n",
        "def predict_nn_labels(X_test, X_train, y_train):\n",
        "    N_test, _, _ = X_test.shape\n",
        "    labels = np.zeros(N_test, dtype=int)\n",
        "\n",
        "    # TODO: Find the label for each image `X_test` using Nearest Neighbors on\n",
        "    # the data `X_train` with labels `y_train` and store the result in `labels`.\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "G37cySyN1J3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test prediction function\n",
        "\n",
        "Similar to the tests for the neighbors and distance functions, these values can be changed to make sure the prediction is correct. For example, for the three training images given, with three labels:\n",
        "```julia\n",
        "mini_y = [17, 12, 2]\n",
        "```\n",
        "the first test \"image\" is closest to train index 0, meaning it should have label 17. The second image is closest to train image 2 so should have label 2. The value of `mini_y_pred` would be `[17, 2]`."
      ],
      "metadata": {
        "id": "CBQ-q0rZ1eoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some tests to make sure the prediction function is correct.\n",
        "mini_y = np.array([17, 12, 2])\n",
        "mini_x_test = np.array([[[1, 2], [3, 3]],\n",
        "                        [[1, 2], [3, 5]]])\n",
        "\n",
        "mini_y_pred = predict_nn_labels(mini_x_test, mini_x_train, mini_y)\n",
        "print(\"Predicted values:\", mini_y_pred)"
      ],
      "metadata": {
        "id": "UTLA2uTK1fpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Nearest Neighbors\n",
        "\n",
        "To test the algorithm, we will use _accuracy_. Accuracy measures the percentage of predicted values which match the true value.\n",
        "\n",
        "First, complete the function below so that it returns the accuracy for predicted labels `y_pred` given the true labels, `y_true`."
      ],
      "metadata": {
        "id": "Af-QD65r1lw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_true):\n",
        "    N, = y_pred.shape\n",
        "    acc = None\n",
        "\n",
        "    # TODO: Compute the accuracy for the predicted labels given the true labels.\n",
        "    return acc"
      ],
      "metadata": {
        "id": "-1lARsSzcfDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will measure the accuracy on all the testing data.\n",
        "\n",
        "Try changing `N_train` and `N_test`. Does changing `N_train` affect the results?\n",
        "\n",
        "*Note:* This might take a while if you increase the size of `N_train` and `N_test`."
      ],
      "metadata": {
        "id": "rrk9iB-DO5mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict_nn_labels(x_test, x_train, y_train)\n",
        "acc = accuracy(y_pred, y_test)\n",
        "print(\"\\nAccuracy:\", acc)"
      ],
      "metadata": {
        "id": "WuGxTFzN1lIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize some results"
      ],
      "metadata": {
        "id": "B-1qUqWN2AF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_viz = 10\n",
        "\n",
        "idx = np.random.choice(np.arange(N_test), num_viz, replace=False)\n",
        "nearest = [nearest_neighbor(x_test[i], x_train) for i in idx]\n",
        "nearest_imgs = x_train[nearest, :, :]\n",
        "imgs = x_test[idx, :, :]\n",
        "\n",
        "for i in range(0, num_viz):\n",
        "    img = idx[i]\n",
        "    print(\"Img\", i, \"-> Predicted:\", y_pred[img], \"True:\", y_test[img])\n",
        "\n",
        "print(\"\\nTop row = test image, bottom row = nearest neighbor.\")\n",
        "img_grid = make_image_grid(np.concatenate((imgs, nearest_imgs)), nrows=2)\n",
        "plt.imshow(img_grid, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "5fBiFvTM2C_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You just implemented a machine learning algorithm for image classification. How did you do? What happens to the accuracy when you change the number of training images, `N_train`? (Remember to rerun the necessary cells when you change the values)."
      ],
      "metadata": {
        "id": "27Pd9u4O3FW6"
      }
    }
  ]
}